{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 1388667,
          "sourceType": "datasetVersion",
          "datasetId": 810652
        },
        {
          "sourceId": 8510885,
          "sourceType": "datasetVersion",
          "datasetId": 5080436
        },
        {
          "sourceId": 8510953,
          "sourceType": "datasetVersion",
          "datasetId": 5080476
        },
        {
          "sourceId": 8526645,
          "sourceType": "datasetVersion",
          "datasetId": 5091775
        },
        {
          "sourceId": 8526668,
          "sourceType": "datasetVersion",
          "datasetId": 5091793
        },
        {
          "sourceId": 8526679,
          "sourceType": "datasetVersion",
          "datasetId": 5091800
        }
      ],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Set a seed for reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directorimport os\n",
        "\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:23.575630Z",
          "iopub.execute_input": "2024-05-27T13:34:23.576075Z",
          "iopub.status.idle": "2024-05-27T13:34:29.538468Z",
          "shell.execute_reply.started": "2024-05-27T13:34:23.576036Z",
          "shell.execute_reply": "2024-05-27T13:34:29.537570Z"
        },
        "trusted": true,
        "id": "3nOzZgxyU6Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/cpuinfo | grep processor"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:29.540516Z",
          "iopub.execute_input": "2024-05-27T13:34:29.541580Z",
          "iopub.status.idle": "2024-05-27T13:34:30.506925Z",
          "shell.execute_reply.started": "2024-05-27T13:34:29.541545Z",
          "shell.execute_reply": "2024-05-27T13:34:30.505936Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veH3j7jiU6P1",
        "outputId": "12d60888-00bb-435c-aad6-cfe5fbf75894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processor\t: 0\n",
            "processor\t: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# envirement related variable\n",
        "n_cpu = 2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:30.508365Z",
          "iopub.execute_input": "2024-05-27T13:34:30.508651Z",
          "iopub.status.idle": "2024-05-27T13:34:30.513549Z",
          "shell.execute_reply.started": "2024-05-27T13:34:30.508625Z",
          "shell.execute_reply": "2024-05-27T13:34:30.512440Z"
        },
        "trusted": true,
        "id": "rqpd_f8vU6P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Data"
      ],
      "metadata": {
        "id": "2jBVqY6zU6P2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root = \"../input/\"\n",
        "root"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:30.514941Z",
          "iopub.execute_input": "2024-05-27T13:34:30.515280Z",
          "iopub.status.idle": "2024-05-27T13:34:30.531205Z",
          "shell.execute_reply.started": "2024-05-27T13:34:30.515249Z",
          "shell.execute_reply": "2024-05-27T13:34:30.530349Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QBbHPlFuU6P4",
        "outputId": "86f6cf10-804e-4681-f5a7-976fa9b19641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'../input/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 256\n",
        "img_width = 256\n",
        "channels = 3"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:30.533579Z",
          "iopub.execute_input": "2024-05-27T13:34:30.533875Z",
          "iopub.status.idle": "2024-05-27T13:34:30.540480Z",
          "shell.execute_reply.started": "2024-05-27T13:34:30.533853Z",
          "shell.execute_reply": "2024-05-27T13:34:30.539575Z"
        },
        "trusted": true,
        "id": "HtylrllkU6P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 0 # epoch to start training from\n",
        "n_epochs = 200 # number of epochs of training\n",
        "batch_size = 1 # size of the batches\n",
        "lr = 0.0002 # adam : learning rate\n",
        "b1 = 0.5 # adam : decay of first order momentum of gradient\n",
        "b2 = 0.999 # adam : decay of first order momentum of gradient\n",
        "decay_epoch = 100 # suggested default : 100 (suggested 'n_epochs' is 200)\n",
        "                 # epoch from which to start lr decay"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:30.541599Z",
          "iopub.execute_input": "2024-05-27T13:34:30.541888Z",
          "iopub.status.idle": "2024-05-27T13:34:30.549176Z",
          "shell.execute_reply.started": "2024-05-27T13:34:30.541857Z",
          "shell.execute_reply": "2024-05-27T13:34:30.548315Z"
        },
        "trusted": true,
        "id": "DRqCvW-kU6P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1), # Pads the input tensor using the reflection of the input boundary\n",
        "            nn.Conv2d(in_features, in_features, 3),\n",
        "            nn.InstanceNorm2d(in_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_features, in_features, 3),\n",
        "            nn.InstanceNorm2d(in_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "\n",
        "class GeneratorResNet(nn.Module):\n",
        "    def __init__(self, input_shape, num_residual_block):\n",
        "        super(GeneratorResNet, self).__init__()\n",
        "\n",
        "        channels = input_shape[0]\n",
        "\n",
        "        # Initial Convolution Block\n",
        "        out_features = 64\n",
        "        model = [\n",
        "            nn.ReflectionPad2d(channels),\n",
        "            nn.Conv2d(channels, out_features, 7),\n",
        "            nn.InstanceNorm2d(out_features),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ]\n",
        "        in_features = out_features\n",
        "\n",
        "        # Downsampling\n",
        "        for _ in range(2):\n",
        "            out_features *= 2\n",
        "            model += [\n",
        "                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(out_features),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ]\n",
        "            in_features = out_features\n",
        "\n",
        "        # Residual blocks\n",
        "        for _ in range(num_residual_block):\n",
        "            model += [ResidualBlock(out_features)]\n",
        "\n",
        "        # Upsampling\n",
        "        for _ in range(2):\n",
        "            out_features //= 2\n",
        "            model += [\n",
        "                nn.Upsample(scale_factor=2), # --> width*2, heigh*2\n",
        "                nn.Conv2d(in_features, out_features, 3, stride=1, padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ]\n",
        "            in_features = out_features\n",
        "\n",
        "        # Output Layer\n",
        "        model += [nn.ReflectionPad2d(channels),\n",
        "                  nn.Conv2d(out_features, channels, 7),\n",
        "                  nn.Tanh()\n",
        "                 ]\n",
        "\n",
        "        # Unpacking\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:30.552062Z",
          "iopub.execute_input": "2024-05-27T13:34:30.552287Z",
          "iopub.status.idle": "2024-05-27T13:34:30.565133Z",
          "shell.execute_reply.started": "2024-05-27T13:34:30.552268Z",
          "shell.execute_reply": "2024-05-27T13:34:30.564316Z"
        },
        "trusted": true,
        "id": "wNEWeB0uU6P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        channels, height, width = input_shape\n",
        "\n",
        "        # Calculate output shape of image discriminator (PatchGAN)\n",
        "        self.output_shape = (1, height//2**4, width//2**4)\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, normalize=True):\n",
        "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
        "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
        "            if normalize:\n",
        "                layers.append(nn.InstanceNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(channels, 64, normalize=False),\n",
        "            *discriminator_block(64, 128),\n",
        "            *discriminator_block(128,256),\n",
        "            *discriminator_block(256,512),\n",
        "            nn.ZeroPad2d((1,0,1,0)),\n",
        "            nn.Conv2d(512, 1, 4, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:30.566148Z",
          "iopub.execute_input": "2024-05-27T13:34:30.566594Z",
          "iopub.status.idle": "2024-05-27T13:34:30.579386Z",
          "shell.execute_reply.started": "2024-05-27T13:34:30.566562Z",
          "shell.execute_reply": "2024-05-27T13:34:30.578538Z"
        },
        "trusted": true,
        "id": "OYUIpuP9U6P7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_cycle = torch.nn.L1Loss()\n",
        "criterion_identity = torch.nn.L1Loss()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:30.580584Z",
          "iopub.execute_input": "2024-05-27T13:34:30.580927Z",
          "iopub.status.idle": "2024-05-27T13:34:30.589824Z",
          "shell.execute_reply.started": "2024-05-27T13:34:30.580899Z",
          "shell.execute_reply": "2024-05-27T13:34:30.588943Z"
        },
        "trusted": true,
        "id": "Nl1270F4U6P8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (channels, img_height, img_width) # (3,256,256)\n",
        "n_residual_blocks = 9 # suggested default, number of residual blocks in generator\n",
        "\n",
        "G_AB = GeneratorResNet(input_shape, n_residual_blocks)\n",
        "G_BA = GeneratorResNet(input_shape, n_residual_blocks)\n",
        "D_A = Discriminator(input_shape)\n",
        "D_B = Discriminator(input_shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:30.590893Z",
          "iopub.execute_input": "2024-05-27T13:34:30.591176Z",
          "iopub.status.idle": "2024-05-27T13:34:30.916103Z",
          "shell.execute_reply.started": "2024-05-27T13:34:30.591154Z",
          "shell.execute_reply": "2024-05-27T13:34:30.915302Z"
        },
        "trusted": true,
        "id": "U6WY0PFzU6P8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "if cuda:\n",
        "    G_AB = G_AB.cuda()\n",
        "    G_BA = G_BA.cuda()\n",
        "    D_A = D_A.cuda()\n",
        "    D_B = D_B.cuda()\n",
        "\n",
        "    criterion_GAN.cuda()\n",
        "    criterion_cycle.cuda()\n",
        "    criterion_identity.cuda()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:30.917317Z",
          "iopub.execute_input": "2024-05-27T13:34:30.917661Z",
          "iopub.status.idle": "2024-05-27T13:34:31.134035Z",
          "shell.execute_reply.started": "2024-05-27T13:34:30.917628Z",
          "shell.execute_reply": "2024-05-27T13:34:31.133157Z"
        },
        "trusted": true,
        "id": "Sow-zQhOU6P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02) # reset Conv2d's weight(tensor) with Gaussian Distribution\n",
        "        if hasattr(m, 'bias') and m.bias is not None:\n",
        "            torch.nn.init.constant_(m.bias.data, 0.0) # reset Conv2d's bias(tensor) with Constant(0)\n",
        "        elif classname.find('BatchNorm2d') != -1:\n",
        "            torch.nn.init.normal_(m.weight.data, 1.0, 0.02) # reset BatchNorm2d's weight(tensor) with Gaussian Distribution\n",
        "            torch.nn.init.constant_(m.bias.data, 0.0) # reset BatchNorm2d's bias(tensor) with Constant(0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:31.135320Z",
          "iopub.execute_input": "2024-05-27T13:34:31.136035Z",
          "iopub.status.idle": "2024-05-27T13:34:31.142933Z",
          "shell.execute_reply.started": "2024-05-27T13:34:31.136000Z",
          "shell.execute_reply": "2024-05-27T13:34:31.141844Z"
        },
        "trusted": true,
        "id": "nsBU4CUnU6P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_AB.apply(weights_init_normal)\n",
        "G_BA.apply(weights_init_normal)\n",
        "D_A.apply(weights_init_normal)\n",
        "D_B.apply(weights_init_normal)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:31.143932Z",
          "iopub.execute_input": "2024-05-27T13:34:31.144200Z",
          "iopub.status.idle": "2024-05-27T13:34:31.190192Z",
          "shell.execute_reply.started": "2024-05-27T13:34:31.144177Z",
          "shell.execute_reply": "2024-05-27T13:34:31.189271Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cezVCinYU6P-",
        "outputId": "807fd609-e322-4385-ed8e-5a5ef75578b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (model): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (11): ZeroPad2d((1, 0, 1, 0))\n",
              "    (12): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "# lr = 0.0002\n",
        "# b1 = 0.5\n",
        "# b2 = 0.999\n",
        "\n",
        "optimizer_G = torch.optim.Adam(\n",
        "    itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=lr, betas=(b1,b2)\n",
        ")\n",
        "\n",
        "optimizer_D_A = torch.optim.Adam(\n",
        "    D_A.parameters(), lr=lr, betas=(b1,b2)\n",
        ")\n",
        "optimizer_D_B = torch.optim.Adam(\n",
        "    D_B.parameters(), lr=lr, betas=(b1,b2)\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:31.195728Z",
          "iopub.execute_input": "2024-05-27T13:34:31.196111Z",
          "iopub.status.idle": "2024-05-27T13:34:31.203636Z",
          "shell.execute_reply.started": "2024-05-27T13:34:31.196085Z",
          "shell.execute_reply": "2024-05-27T13:34:31.202574Z"
        },
        "trusted": true,
        "id": "DPpgicqDU6P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LambdaLR:\n",
        "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
        "        assert (n_epochs - decay_start_epoch) > 0, \"Decay must start before the training session ends!\"\n",
        "        self.n_epochs = n_epochs\n",
        "        self.offset = offset\n",
        "        self.decay_start_epoch = decay_start_epoch\n",
        "\n",
        "    def step(self, epoch):\n",
        "        return 1.0 - max(0, epoch+self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:31.205117Z",
          "iopub.execute_input": "2024-05-27T13:34:31.206099Z",
          "iopub.status.idle": "2024-05-27T13:34:31.214301Z",
          "shell.execute_reply.started": "2024-05-27T13:34:31.206063Z",
          "shell.execute_reply": "2024-05-27T13:34:31.213430Z"
        },
        "trusted": true,
        "id": "kMPtDE-nU6P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n",
        "    optimizer_G,\n",
        "    lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n",
        ")\n",
        "\n",
        "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(\n",
        "    optimizer_D_A,\n",
        "    lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n",
        ")\n",
        "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(\n",
        "    optimizer_D_B,\n",
        "    lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:31.215624Z",
          "iopub.execute_input": "2024-05-27T13:34:31.216182Z",
          "iopub.status.idle": "2024-05-27T13:34:31.228788Z",
          "shell.execute_reply.started": "2024-05-27T13:34:31.216139Z",
          "shell.execute_reply": "2024-05-27T13:34:31.227973Z"
        },
        "trusted": true,
        "id": "4cWrwiumU6P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "transforms_ = [\n",
        "    transforms.Resize(int(img_height*1.12), Image.BICUBIC),\n",
        "    transforms.RandomCrop((img_height, img_width)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:31.229836Z",
          "iopub.execute_input": "2024-05-27T13:34:31.230112Z",
          "iopub.status.idle": "2024-05-27T13:34:31.240314Z",
          "shell.execute_reply.started": "2024-05-27T13:34:31.230089Z",
          "shell.execute_reply": "2024-05-27T13:34:31.239486Z"
        },
        "trusted": true,
        "id": "sAc8jxnLU6P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_rgb(image):\n",
        "    rgb_image = Image.new(\"RGB\", image.size)\n",
        "    rgb_image.paste(image)\n",
        "    return rgb_image"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:31.241279Z",
          "iopub.execute_input": "2024-05-27T13:34:31.241530Z",
          "iopub.status.idle": "2024-05-27T13:34:31.250660Z",
          "shell.execute_reply.started": "2024-05-27T13:34:31.241509Z",
          "shell.execute_reply": "2024-05-27T13:34:31.249895Z"
        },
        "trusted": true,
        "id": "TWsyzMiTU6P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(root)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:31.251657Z",
          "iopub.execute_input": "2024-05-27T13:34:31.252003Z",
          "iopub.status.idle": "2024-05-27T13:34:31.262943Z",
          "shell.execute_reply.started": "2024-05-27T13:34:31.251980Z",
          "shell.execute_reply": "2024-05-27T13:34:31.262065Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqaaYlgiU6P_",
        "outputId": "caaf5d1f-ea3f-40dc-ffb3-8d031d2c0cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "../input/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paintings_dataset_path = os.path.join(root,\"van-gogh-paintings\",\"VincentVanGogh\",'**', )\n",
        "photo_dataset_path = os.path.join(root,\"vangogh2photo\",\"vangogh2photo\",\"trainB\",\"*.*\")\n",
        "\n",
        "print(len(glob.glob(paintings_dataset_path)))\n",
        "print(len(glob.glob(photo_dataset_path,recursive=True)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:31.263933Z",
          "iopub.execute_input": "2024-05-27T13:34:31.264224Z",
          "iopub.status.idle": "2024-05-27T13:34:31.946507Z",
          "shell.execute_reply.started": "2024-05-27T13:34:31.264196Z",
          "shell.execute_reply": "2024-05-27T13:34:31.945490Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pvgo-FBU6P_",
        "outputId": "929af8f7-2522-4617-d6bb-0da4f79a6743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root, transforms_=None, stratified = False, unaligned=False, mode='train',val_percentage=0.1,test_percentage=0.1):\n",
        "        self.transform = transforms.Compose(transforms_)\n",
        "        self.unaligned = unaligned\n",
        "        self.mode = mode\n",
        "        self.stratified = stratified\n",
        "        self.files_A = glob.glob(os.path.join(root,\"vangogh2photo\",\"vangogh2photo\",\"trainA\",\"*.*\"),recursive=True)\n",
        "        random.shuffle(self.files_A)\n",
        "        self.files_B = glob.glob(os.path.join(root,\"vangogh2photo\",\"vangogh2photo\",\"trainB\",\"*.*\"),recursive=True)[:400]\n",
        "        random.shuffle(self.files_A)\n",
        "        random.shuffle(self.files_B)\n",
        "        self.filesA_val_size = int(len(self.files_A) * val_percentage)\n",
        "        self.filesA_test_size = int(len(self.files_A) * test_percentage)\n",
        "        self.filesA_train_size = len(self.files_A) -  self.filesA_val_size - self.filesA_test_size\n",
        "        self.filesB_val_size = int(len(self.files_B) * val_percentage)\n",
        "        self.filesB_test_size = int(len(self.files_B) * test_percentage)\n",
        "        self.filesB_train_size = len(self.files_B) -  self.filesB_val_size - self.filesB_test_size\n",
        "        if self.stratified :\n",
        "            paintings_cat_path = os.path.join(root,\"van-gogh-paintings\",\"VincentVanGogh\",'**')\n",
        "            self.strata =  glob.glob(paintings_cat_path)\n",
        "            idx = self.files_A_train_size // len(self.strata)\n",
        "            for file in self.strata :\n",
        "                     paintings_path = os.path.join(root,\"van-gogh-paintings\",\"VincentVanGogh\",file,\"*.*\")\n",
        "                     paintings = os.glob(paintings_path,recursive=True)\n",
        "                     random.shuffle(paintings)\n",
        "                     if self.mode == 'train' :\n",
        "                             train_size = (len(self.files_A)//len(paintings)) * ((1 - val_percentage - test_percentage) // len(self.strata))\n",
        "                             print(train_size)\n",
        "                             self.files_A += paintings[:train_size]\n",
        "                     if self.mode == 'val' :\n",
        "                             val_size = (len(self.files_A)//len(paintings)) * (val_percentage  // len(self.strata))\n",
        "                             print(val_size)\n",
        "                             self.files_A += paintings[train_size:val_size]\n",
        "                     if self.mode == 'test' :\n",
        "                             test_size = (len(self.files_A)//len(paintings)) * (test_percentage  // len(self.strata))\n",
        "                             print(test_size)\n",
        "                             self.files_A += paintings[val_size:]\n",
        "            if self.mode == 'train':\n",
        "                        self.files_B = self.files_B[:self.filesB_train_size]\n",
        "            if self.mode == 'val':\n",
        "                        self.files_B = self.files_B[self.filesB_train_size:self.filesB_val_size]\n",
        "            if self.mode == 'test':\n",
        "                        self.files_B = self.files_B[self.filesB_val_size:]\n",
        "        else :\n",
        "            if self.mode == 'train':\n",
        "                        self.files_A = self.files_A[:self.filesA_train_size]\n",
        "                        self.files_B = self.files_B[:self.filesB_train_size]\n",
        "            if self.mode == 'val':\n",
        "                        self.files_A = self.files_A[self.filesA_train_size:self.filesA_val_size+self.filesA_train_size]\n",
        "                        self.files_B = self.files_B[self.filesB_train_size:self.filesB_val_size+self.filesB_train_size]\n",
        "            if self.mode == 'test':\n",
        "                        self.files_A = self.files_A[self.filesA_val_size+self.filesA_train_size:]\n",
        "                        self.files_B = self.files_B[self.filesB_val_size+self.filesB_train_size:]\n",
        "    def  __getitem__(self, index):\n",
        "        image_A = Image.open(self.files_A[index % len(self.files_A)])\n",
        "        image_B = Image.open(self.files_B[index % len(self.files_B)])\n",
        "        if image_A.mode != 'RGB':\n",
        "            image_A = to_rgb(image_A)\n",
        "        if image_B.mode != 'RGB':\n",
        "            image_B = to_rgb(image_B)\n",
        "\n",
        "        item_A = self.transform(image_A)\n",
        "        item_B = self.transform(image_B)\n",
        "        return {'A':item_A, 'B':item_B}\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return max(len(self.files_A), len(self.files_B))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:31.947585Z",
          "iopub.execute_input": "2024-05-27T13:34:31.947885Z",
          "iopub.status.idle": "2024-05-27T13:34:31.969463Z",
          "shell.execute_reply.started": "2024-05-27T13:34:31.947860Z",
          "shell.execute_reply": "2024-05-27T13:34:31.968451Z"
        },
        "trusted": true,
        "id": "VrfMtqNGU6P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(ImageDataset(root, transforms_=transforms_))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:31.970552Z",
          "iopub.execute_input": "2024-05-27T13:34:31.970856Z",
          "iopub.status.idle": "2024-05-27T13:34:32.161341Z",
          "shell.execute_reply.started": "2024-05-27T13:34:31.970825Z",
          "shell.execute_reply": "2024-05-27T13:34:32.160417Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDRrl4E_U6QA",
        "outputId": "bae7b0b9-9466-4179-b494-bb4d6c8b86fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(\n",
        "    ImageDataset(root, transforms_=transforms_),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=n_cpu # 3\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    ImageDataset(root, transforms_=transforms_,mode=\"test\"),\n",
        "    batch_size=5, # 1\n",
        "    shuffle=True,\n",
        "    num_workers=n_cpu # 3\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    ImageDataset(root, transforms_=transforms_, mode='val'),\n",
        "    batch_size=10,\n",
        "    shuffle=True,\n",
        "    num_workers=n_cpu\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:32.162331Z",
          "iopub.execute_input": "2024-05-27T13:34:32.162575Z",
          "iopub.status.idle": "2024-05-27T13:34:32.245079Z",
          "shell.execute_reply.started": "2024-05-27T13:34:32.162554Z",
          "shell.execute_reply": "2024-05-27T13:34:32.244268Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "zuZzyaklU6QA",
        "outputId": "8f87fb7e-731c-43e4-d8fe-34e844a81d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "num_samples should be a positive integer value, but got num_samples=0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-db3640b66a37>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m dataloader = DataLoader(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_cpu\u001b[0m \u001b[0;31m# 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"num_samples should be a positive integer value, but got num_samples={self.num_samples}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
        "def sample_images():\n",
        "    \"\"\"show a generated sample from the test set\"\"\"\n",
        "    imgs = next(iter(val_dataloader))\n",
        "    G_AB.eval()\n",
        "    G_BA.eval()\n",
        "    real_A = imgs['A'].type(Tensor) #A van gogh\n",
        "    real_B = imgs['B'].type(Tensor) # B : photo\n",
        "    fake_B = G_AB(real_A).detach()\n",
        "    fake_A = G_BA(real_B).detach()\n",
        "    # Arange images along x-axis\n",
        "    real_A = make_grid(real_A, nrow=5, normalize=True)\n",
        "    fake_B = make_grid(fake_B, nrow=5, normalize=True)\n",
        "    real_B = make_grid(real_B, nrow=5, normalize=True)\n",
        "    fake_A = make_grid(fake_A, nrow=5, normalize=True)\n",
        "    # Arange images along y-axis\n",
        "    image_grid = torch.cat((real_A, fake_B, real_B, fake_A), 1)\n",
        "    plt.imshow(image_grid.cpu().permute(1,2,0))\n",
        "    plt.title('Real A vs Fake B | Real B vs Fake A')\n",
        "    plt.axis('off')\n",
        "    plt.show();"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:32.246354Z",
          "iopub.execute_input": "2024-05-27T13:34:32.246980Z",
          "iopub.status.idle": "2024-05-27T13:34:32.255833Z",
          "shell.execute_reply.started": "2024-05-27T13:34:32.246946Z",
          "shell.execute_reply": "2024-05-27T13:34:32.254817Z"
        },
        "trusted": true,
        "id": "v5ilsqThU6QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_imgs = next(iter(test_dataloader))\n",
        "G_AB.eval() # test mode\n",
        "G_BA.eval() # test mode\n",
        "print(temp_imgs['A'].shape)\n",
        "print(temp_imgs['B'].shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:32.256968Z",
          "iopub.execute_input": "2024-05-27T13:34:32.257299Z",
          "iopub.status.idle": "2024-05-27T13:34:32.710591Z",
          "shell.execute_reply.started": "2024-05-27T13:34:32.257268Z",
          "shell.execute_reply": "2024-05-27T13:34:32.709473Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "YCmqOOonU6QA",
        "outputId": "2df23d48-1710-4124-ac30-3e704eddb487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_dataloader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-4ef0fb5e1bcb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mG_AB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# test mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mG_BA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# test mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_dataloader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_real_A = temp_imgs['A'].type(Tensor) # A : van gogh\n",
        "temp_fake_B = G_AB(temp_real_A).detach()\n",
        "temp_real_B = temp_imgs['B'].type(Tensor) # B : photo\n",
        "temp_fake_A = G_BA(temp_real_B).detach()\n",
        "print(temp_real_A.shape)\n",
        "print(temp_fake_B.shape)\n",
        "print(temp_real_B.shape)\n",
        "print(temp_fake_A.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:32.712004Z",
          "iopub.execute_input": "2024-05-27T13:34:32.712286Z",
          "iopub.status.idle": "2024-05-27T13:34:33.306234Z",
          "shell.execute_reply.started": "2024-05-27T13:34:32.712259Z",
          "shell.execute_reply": "2024-05-27T13:34:33.305308Z"
        },
        "trusted": true,
        "id": "rTRB1DLEU6QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_real_A = make_grid(temp_real_A, nrow=5, normalize=True)\n",
        "temp_real_B = make_grid(temp_real_B, nrow=5, normalize=True)\n",
        "temp_fake_A = make_grid(temp_fake_A, nrow=5, normalize=True)\n",
        "temp_fake_B = make_grid(temp_fake_B, nrow=5, normalize=True)\n",
        "temp_image_grid = torch.cat((temp_real_A, temp_fake_A, temp_real_B, temp_fake_B), 1)\n",
        "plt.imshow(temp_image_grid.cpu().permute(1,2,0))\n",
        "plt.title('Real A | Fake B | Real B | Fake A ')\n",
        "plt.axis('off');"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:33.307581Z",
          "iopub.execute_input": "2024-05-27T13:34:33.307904Z",
          "iopub.status.idle": "2024-05-27T13:34:34.076219Z",
          "shell.execute_reply.started": "2024-05-27T13:34:33.307880Z",
          "shell.execute_reply": "2024-05-27T13:34:34.075360Z"
        },
        "trusted": true,
        "id": "l-ccDsXsU6QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:34.077246Z",
          "iopub.execute_input": "2024-05-27T13:34:34.077519Z",
          "iopub.status.idle": "2024-05-27T13:34:34.083245Z",
          "shell.execute_reply.started": "2024-05-27T13:34:34.077496Z",
          "shell.execute_reply": "2024-05-27T13:34:34.082282Z"
        },
        "trusted": true,
        "id": "4olkOXx3U6QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer():\n",
        "    def __init__(self, max_size=50):\n",
        "        assert (max_size > 0), 'Empty buffer or trying to create a black hole. Be careful.'\n",
        "        self.max_size = max_size\n",
        "        self.data = []\n",
        "\n",
        "    def push_and_pop(self, data):\n",
        "        to_return = []\n",
        "        for element in data.data:\n",
        "            element = torch.unsqueeze(element, 0)\n",
        "            if len(self.data) < self.max_size:\n",
        "                self.data.append(element)\n",
        "                to_return.append(element)\n",
        "            else:\n",
        "                if random.uniform(0,1) > 0.5:\n",
        "                    i = random.randint(0, self.max_size-1)\n",
        "                    to_return.append(self.data[i].clone())\n",
        "                    self.data[i] = element\n",
        "                else:\n",
        "                    to_return.append(element)\n",
        "        return torch.cat(to_return)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:34:34.084432Z",
          "iopub.execute_input": "2024-05-27T13:34:34.084805Z",
          "iopub.status.idle": "2024-05-27T13:34:34.093028Z",
          "shell.execute_reply.started": "2024-05-27T13:34:34.084755Z",
          "shell.execute_reply": "2024-05-27T13:34:34.092169Z"
        },
        "trusted": true,
        "id": "TQeC86_bU6QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_generated_images(epoch):\n",
        "    imgs = next(iter(val_dataloader))\n",
        "    G_AB.eval()\n",
        "    G_BA.eval()\n",
        "    real_A = imgs['A'].type(Tensor) #A van gogh\n",
        "    real_B = imgs['B'].type(Tensor) # B : photo\n",
        "    fake_B = G_AB(real_A).detach()\n",
        "    fake_A = G_BA(real_B).detach()\n",
        "    # Arange images along x-axis\n",
        "    real_A = make_grid(real_A, nrow=5, normalize=True)\n",
        "    real_B = make_grid(real_B, nrow=5, normalize=True)\n",
        "    fake_A = make_grid(fake_A, nrow=5, normalize=True)\n",
        "    real_A = real_A.permute(1, 2, 0).cpu().numpy()\n",
        "    real_A = (real_A * 255).astype(np.uint8)  # Optional: scale to [0, 255]\n",
        "    fake_A = fake_A.permute(1, 2, 0).cpu().numpy()\n",
        "    fake_A = (fake_A * 255).astype(np.uint8)\n",
        "    real_B = real_B.permute(1, 2, 0).cpu().numpy()\n",
        "    real_B = (real_B * 255).astype(np.uint8)\n",
        "    # Optional: scale to\n",
        "    wandb.log({\"generated_images\": [wandb.Image(fake_A, caption=f\"van gogh paintings Epoch {epoch}\"),wandb.Image(real_B, caption=f\" real images  Epoch {epoch}\"),wandb.Image(real_A, caption=f\" real van gogh paintings  Epoch {epoch}\")]})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T13:35:11.173950Z",
          "iopub.execute_input": "2024-05-27T13:35:11.174335Z",
          "iopub.status.idle": "2024-05-27T13:35:11.184199Z",
          "shell.execute_reply.started": "2024-05-27T13:35:11.174308Z",
          "shell.execute_reply": "2024-05-27T13:35:11.183030Z"
        },
        "trusted": true,
        "id": "p7yIDqvTU6QD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}